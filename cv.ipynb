{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import filters\n",
    "from skimage.morphology import disk, opening\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import time\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to a sample image (replace if needed; note dataset has 'notumor' not 'no_tumor')\n",
    "sample_img_path = '/Users/tuhinalambijoy/Downloads/brain_tumor_dataset/Training/glioma/Tr-gl_0010.jpg'\n",
    "\n",
    "# Load image\n",
    "img = cv2.imread(sample_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Output: Original Image\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title('Original Image')\n",
    "plt.show()\n",
    "\n",
    "# Description of Change: Image loaded as grayscale. No changes yet.\n",
    "#  The output shows a raw MRI scan with possible low contrast and noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLAHE for contrast enhancement\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "enhanced_img = clahe.apply(img)\n",
    "\n",
    "# Output: Enhanced Image\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(enhanced_img, cmap='gray')\n",
    "plt.title('Enhanced Image (CLAHE)')\n",
    "plt.show()\n",
    "\n",
    "# Description of Change: Contrast is improved,\n",
    "#  making tumor regions more distinguishable from healthy tissue.\n",
    "#  Brighter areas are amplified, but noise might increase slightly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median filter for noise removal\n",
    "denoised_img = cv2.medianBlur(enhanced_img, 5)\n",
    "\n",
    "# Output: Denoised Image\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(denoised_img, cmap='gray')\n",
    "plt.title('Denoised Image (Median Filter)')\n",
    "plt.show()\n",
    "\n",
    "# Description of Change: Removes speckle noise, smoothing the image while preserving edges.\n",
    "#  Tumor boundaries remain intact, but fine details might be slightly blurred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canny edge detection\n",
    "edges = cv2.Canny(denoised_img, 30, 150)\n",
    "\n",
    "# Output: Edges\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(edges, cmap='gray')\n",
    "plt.title('Edge Detection (Canny)')\n",
    "plt.show()\n",
    "\n",
    "# Description of Change: Highlights boundaries, including tumor edges.\n",
    "#  White lines indicate strong gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otsu's thresholding\n",
    "thresh_val = filters.threshold_otsu(denoised_img)\n",
    "segmented_img = denoised_img > thresh_val\n",
    "\n",
    "# Convert to uint8 for morphology\n",
    "segmented_img = (segmented_img * 255).astype(np.uint8)\n",
    "\n",
    "# Output: Segmented Image\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(segmented_img, cmap='gray')\n",
    "plt.title('Segmented Image (Otsu Thresholding)')\n",
    "plt.show()\n",
    "\n",
    "# Description of Change: Binarizes the image,\n",
    "#  separating foreground (potential tumor) from background. Tumor region appears white."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Morphological opening\n",
    "kernel = disk(3)\n",
    "post_processed_img = opening(segmented_img, kernel)\n",
    "\n",
    "# Find contours\n",
    "contours, _ = cv2.findContours(post_processed_img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Draw contours on original for visualization\n",
    "contoured_img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "cv2.drawContours(contoured_img, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "# Output: Post-Processed and Contoured Image\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(cv2.cvtColor(contoured_img, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Post-Processed (Morphology) with Contours')\n",
    "plt.show()\n",
    "\n",
    "# Description of Change: Removes small artifacts, smooths the mask. Contours highlight the segmented tumor region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Definition and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 32 * 32, 128)  # For 128x128 input\n",
    "        self.fc2 = nn.Linear(128, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 32 * 32)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class BrainTumorDataset(Dataset):\n",
    "    def __init__(self, root_dir, preprocess=True):\n",
    "        self.root_dir = root_dir\n",
    "        self.preprocess = preprocess\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        classes = ['glioma', 'meningioma', 'notumor', 'pituitary']  # Corrected class names\n",
    "        for idx, cls in enumerate(classes):\n",
    "            path = os.path.join(root_dir, cls)\n",
    "            if os.path.exists(path):\n",
    "                for img_name in os.listdir(path):\n",
    "                    self.images.append(os.path.join(path, img_name))\n",
    "                    self.labels.append(idx)\n",
    "            else:\n",
    "                print(f\"Warning: Path {path} does not exist.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.images[idx]\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if self.preprocess:\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "            img = clahe.apply(img)\n",
    "            img = cv2.medianBlur(img, 5)\n",
    "        img = cv2.resize(img, (128, 128))\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        img = torch.from_numpy(img).unsqueeze(0)\n",
    "        label = self.labels[idx]\n",
    "        return img, label\n",
    "\n",
    "def train_cnn(train_dir, test_dir, preprocess=True, epochs=5):\n",
    "    train_dataset = BrainTumorDataset(train_dir, preprocess=preprocess)\n",
    "    test_dataset = BrainTumorDataset(test_dir, preprocess=preprocess)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "    \n",
    "    model = SimpleCNN().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    print(f\"Starting training ({'with' if preprocess else 'without'} preprocessing)...\")\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader):.4f}')\n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "    proc_time = (time.time() - start_time) / len(test_dataset)\n",
    "    \n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average='macro')\n",
    "    rec = recall_score(y_true, y_pred, average='macro')\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    \n",
    "    print(f\"Evaluation complete -> Accuracy: {acc:.4f}, F1: {f1:.4f}\")\n",
    "    \n",
    "    return acc, prec, rec, f1, proc_time, model  # Return the trained model too!\n",
    "\n",
    "# Paths (adjust if needed)\n",
    "train_dir = '/Users/tuhinalambijoy/Downloads/brain_tumor_dataset/Training'\n",
    "test_dir = '/Users/tuhinalambijoy/Downloads/brain_tumor_dataset/Testing'\n",
    "\n",
    "print(\"=== Training Model WITH Preprocessing ===\")\n",
    "acc_with, prec_with, rec_with, f1_with, time_with, model_with = train_cnn(\n",
    "    train_dir, test_dir, preprocess=True, epochs=5\n",
    ")\n",
    "\n",
    "print(\"\\n=== Training Model WITHOUT Preprocessing ===\")\n",
    "acc_without, prec_without, rec_without, f1_without, time_without, model_without = train_cnn(\n",
    "    train_dir, test_dir, preprocess=False, epochs=5\n",
    ")\n",
    "\n",
    "# Save the trained models for later use (inference on new images)\n",
    "torch.save(model_with.state_dict(), 'brain_tumor_model_with_preprocess.pth')\n",
    "torch.save(model_without.state_dict(), 'brain_tumor_model_without_preprocess.pth')\n",
    "\n",
    "print(\"\\nTraining complete! Models saved.\")\n",
    "print(f\"With Preprocessing -> Acc: {acc_with:.4f}, F1: {f1_with:.4f}, Time/img: {time_with:.6f}s\")\n",
    "print(f\"Without Preprocessing -> Acc: {acc_without:.4f}, F1: {f1_without:.4f}, Time/img: {time_without:.6f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test a New MRI Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_new_mri(image_path, use_preprocessing=True):\n",
    "    model_path = 'brain_tumor_model_with_preprocess.pth' if use_preprocessing else 'brain_tumor_model_without_preprocess.pth'\n",
    "    \n",
    "    model = SimpleCNN().to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    \n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        print(\"Error: Image not found. Check the path.\")\n",
    "        return None\n",
    "    \n",
    "    if use_preprocessing:\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        img = clahe.apply(img)\n",
    "        img = cv2.medianBlur(img, 5)\n",
    "    \n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    img_tensor = torch.from_numpy(img).unsqueeze(0).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        probabilities = torch.softmax(output, dim=1)\n",
    "        confidence, predicted = torch.max(probabilities, 1)\n",
    "    \n",
    "    classes = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "    prediction = classes[predicted.item()]\n",
    "    conf = confidence.item()\n",
    "    \n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.imshow(cv2.imread(image_path, cv2.IMREAD_GRAYSCALE), cmap='gray')\n",
    "    if prediction == 'notumor':\n",
    "        plt.title(f'NO TUMOR DETECTED\\nConfidence: {conf:.1%}', color='green', fontsize=18)\n",
    "    else:\n",
    "        plt.title(f'TUMOR DETECTED: {prediction.upper()}\\nConfidence: {conf:.1%}', color='red', fontsize=18)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return prediction, conf\n",
    "\n",
    "# === TEST A NEW IMAGE ===\n",
    "new_image_path = '/Users/tuhinalambijoy/Desktop/images (1).jpeg'  # CHANGE THIS TO YOUR ACTUAL IMAGE PATH\n",
    "\n",
    "result, confidence = predict_new_mri(new_image_path, use_preprocessing=True)\n",
    "if result:\n",
    "    print(f\"Prediction: {result} (confidence: {confidence:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_new_mri(image_path, use_preprocessing=True):\n",
    "    model_path = 'brain_tumor_model_with_preprocess.pth' if use_preprocessing else 'brain_tumor_model_without_preprocess.pth'\n",
    "    \n",
    "    model = SimpleCNN().to(device)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()\n",
    "    \n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        print(\"Error: Image not found. Check the path.\")\n",
    "        return None\n",
    "    \n",
    "    if use_preprocessing:\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "        img = clahe.apply(img)\n",
    "        img = cv2.medianBlur(img, 5)\n",
    "    \n",
    "    img = cv2.resize(img, (128, 128))\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    img_tensor = torch.from_numpy(img).unsqueeze(0).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)\n",
    "        probabilities = torch.softmax(output, dim=1)\n",
    "        confidence, predicted = torch.max(probabilities, 1)\n",
    "    \n",
    "    classes = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
    "    prediction = classes[predicted.item()]\n",
    "    conf = confidence.item()\n",
    "    \n",
    "    plt.figure(figsize=(7,7))\n",
    "    plt.imshow(cv2.imread(image_path, cv2.IMREAD_GRAYSCALE), cmap='gray')\n",
    "    if prediction == 'notumor':\n",
    "        plt.title(f'NO TUMOR DETECTED\\nConfidence: {conf:.1%}', color='green', fontsize=18)\n",
    "    else:\n",
    "        plt.title(f'TUMOR DETECTED: {prediction.upper()}\\nConfidence: {conf:.1%}', color='red', fontsize=18)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return prediction, conf\n",
    "\n",
    "# === TEST A NEW IMAGE ===\n",
    "new_image_path = '/Users/tuhinalambijoy/Downloads/brain_tumor_dataset/Testing/pituitary/Te-pi_0043.jpg'  # CHANGE THIS TO YOUR ACTUAL IMAGE PATH\n",
    "\n",
    "result, confidence = predict_new_mri(new_image_path, use_preprocessing=True)\n",
    "if result:\n",
    "    print(f\"Prediction: {result} (confidence: {confidence:.1%})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
